{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_origin = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp = re.compile('(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
    "en_nlp = spacy.load('en')\n",
    "old_tokenizer = en_nlp.tokenizer\n",
    "en_nlp.tokenizer = lambda string: old_tokenizer.tokens_from_list(regexp.findall(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(document):\n",
    "    doc_spacy = en_nlp(document)\n",
    "    return [token.lemma_ for token in doc_spacy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\masato\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: [W002] Tokenizer.from_list is now deprecated. Create a new Doc object instead and pass in the strings as the `words` keyword argument, for example:\n",
      "from spacy.tokens import Doc\n",
      "doc = Doc(nlp.vocab, words=[...])\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(tokenizer=custom_tokenizer,min_df=5,stop_words=\"english\",ngram_range=(1,3))\n",
    "X_train_counts = count_vect.fit_transform(data_origin.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transformer = TfidfTransformer().fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=0.01).fit(X_train_tfidf,data_origin.jobflag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\masato\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: [W002] Tokenizer.from_list is now deprecated. Create a new Doc object instead and pass in the strings as the `words` keyword argument, for example:\n",
      "from spacy.tokens import Doc\n",
      "doc = Doc(nlp.vocab, words=[...])\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "X_new_counts = count_vect.transform(data_test.description)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['pre'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.to_csv('submit_alpha01stopmin5n3lemma.csv',columns=['id','pre'],header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(X_train_counts.toarray(), columns=count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>-PRON- -PRON-</th>\n",
       "      <th>-PRON- business</th>\n",
       "      <th>-PRON- client</th>\n",
       "      <th>-PRON- company</th>\n",
       "      <th>-PRON- current</th>\n",
       "      <th>-PRON- customer</th>\n",
       "      <th>-PRON- datum</th>\n",
       "      <th>-PRON- need</th>\n",
       "      <th>-PRON- partner</th>\n",
       "      <th>...</th>\n",
       "      <th>work product</th>\n",
       "      <th>work project</th>\n",
       "      <th>work stakeholder</th>\n",
       "      <th>work stream</th>\n",
       "      <th>work team</th>\n",
       "      <th>workflow</th>\n",
       "      <th>workshop</th>\n",
       "      <th>world</th>\n",
       "      <th>write</th>\n",
       "      <th>write unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1382 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   -PRON-  -PRON- -PRON-  -PRON- business  -PRON- client  -PRON- company  \\\n",
       "0       0              0                0              0               0   \n",
       "1       0              0                0              0               0   \n",
       "2       0              0                0              0               0   \n",
       "3       0              0                0              0               0   \n",
       "4       0              0                0              0               0   \n",
       "\n",
       "   -PRON- current  -PRON- customer  -PRON- datum  -PRON- need  -PRON- partner  \\\n",
       "0               0                0             0            0               0   \n",
       "1               0                0             0            0               0   \n",
       "2               0                0             0            0               0   \n",
       "3               0                0             0            0               0   \n",
       "4               0                0             0            0               0   \n",
       "\n",
       "      ...      work product  work project  work stakeholder  work stream  \\\n",
       "0     ...                 0             0                 0            0   \n",
       "1     ...                 0             0                 0            0   \n",
       "2     ...                 0             0                 0            0   \n",
       "3     ...                 0             0                 0            0   \n",
       "4     ...                 0             0                 0            0   \n",
       "\n",
       "   work team  workflow  workshop  world  write  write unit  \n",
       "0          0         0         0      0      1           0  \n",
       "1          0         0         0      0      0           0  \n",
       "2          0         0         0      0      0           0  \n",
       "3          0         0         0      0      0           0  \n",
       "4          0         0         0      0      0           0  \n",
       "\n",
       "[5 rows x 1382 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
